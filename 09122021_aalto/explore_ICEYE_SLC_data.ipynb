{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c9a6e1",
   "metadata": {},
   "source": [
    "This short example uses the ICEYE <a href=\"https://github.com/iceye-ltd/icecube\">ICEcube library</a> and inherents it's dependencies. Install ICEcube using the <a href=\"https://iceye-ltd.github.io/icecube/installation/\">installation instructions</a>.\n",
    "\n",
    "You can easily download an ICEYE image here: https://www.iceye.com/lp/example-strip-sar-dataset-acre-brazil. This data is a set of time-series data over Acre, Brazil over a forested region of the Amazon.\n",
    "\n",
    "Learn to uce the ICEcube library to read in the data (at least 1 image), and run a (rather naive and meaingless) kmeans clustering to try to classify like pixels in either the complex or real domain. This is just an exercise to show you how to handle the data arrays and start thinking about techniques you could leverage to assess patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a4333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an ICEYE image or 2 from here: https://www.iceye.com/lp/example-strip-sar-dataset-acre-brazil\n",
    "# They can be large, so it may take a while \n",
    "\n",
    "# Hierarchical Data Format (HDF) of ICEYE SLC imagery\n",
    "import icecube\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from icecube.bin.sar_cube.slc_datacube import SLCDatacube\n",
    "from icecube.bin.sar_cube.grd_datacube import GRDDatacube\n",
    "from icecube.bin.config import CubeConfig \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dec05c",
   "metadata": {},
   "source": [
    "Put the SLC images in 1 folder and the GRDs in another folder. It can help to get things organized. I only have 1 image in each folder.\n",
    "\n",
    "```\n",
    "├── grds\n",
    "│   └── ICEYE_GRD_SM_71820_20210722T055012.tif\n",
    "└── slcs\n",
    "    ├── ICEYE_SLC_SM_71820_20210722T055012.h5\n",
    "    ├── ICEYE_SLC_SM_71820_20210722T055012.xml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438cc732",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_config = CubeConfig()\n",
    "slc_datacube = SLCDatacube.build(cube_config, 'slcs')\n",
    "grd_datacube = GRDDatacube.build(cube_config, 'grds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad290d",
   "metadata": {},
   "source": [
    "Each image pixel is represented by a complex (I and Q) magnitude value and therefore contains both amplitude and phase information. The processing for all SLC products results in a single look in each dimension using the full available signal bandwidth. The imagery is geo-referenced using orbit and attitude data from the satellite. SLC images are produced in a zero Doppler geometry. This convention is common with the standard slant range products available from other SAR sensors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1fdb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the data look like?\n",
    "\n",
    "slc_datacube.xrdataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e47a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slc_datacube.xrdataset['Real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839cf2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "slc_datacube.xrdataset['Complex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6218acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "slc_datacube.xrdataset['Complex'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa2dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grd_datacube.xrdataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da9450",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity=grd_datacube.xrdataset['Intensity'][0].values\n",
    "intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7da88",
   "metadata": {},
   "source": [
    "These are really big files (GB each!) But we use the memory optimized xarray format to handle this. Visualing can take a while here though, so let's just focus on a small subset. I am going to create a 2k x 2k chip(s).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db502d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at an amplitude chunk!\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(intensity[1000:3000, 1000:3000])\n",
    "ax[1].imshow(intensity[3001:5001, 3001:5001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0050fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl=slc_datacube.xrdataset['Real'][0].values\n",
    "cmplx=slc_datacube.xrdataset['Complex'][0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a379795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we can crop the real and complex imagery, similarly to the GRD above.\n",
    "crop_rl_tr = rl[1000:3000, 1000:3000]\n",
    "crop_rl_tst = rl[3001:5001, 3001:5001]\n",
    "crop_cl_tr = cmplx[1000:3000, 1000:3000]\n",
    "crop_cl_tst = cmplx[3001:5001, 3001:5001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1f1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the complex/real image chips\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(abs(crop_rl_tst))\n",
    "ax[1].imshow(abs(crop_cl_tst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf35d3bb",
   "metadata": {},
   "source": [
    "Now, let's make a kmeans classifier that attempts to cluster the pixels by type to create a 'poor-mans' semantic segmentor. To use kmeans, we have to typically flatten the 2D array to 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_f_tr=crop_rl_tr.flatten().reshape(-1, 1)     #for k-means must be 1D\n",
    "rl_f_tst=crop_rl_tst.flatten().reshape(-1, 1)     #for k-means must be 1D\n",
    "\n",
    "cl_f_tr=crop_cl_tr.flatten().reshape(-1, 1)     #for k-means must be 1D\n",
    "cl_f_tst=crop_cl_tst.flatten().reshape(-1, 1)     #for k-means must be 1D\n",
    "\n",
    "in_f_tst=intensity[3001:5001, 3001:5001].flatten().reshape(-1, 1)\n",
    "#cmplx_f=cmplx.flatten().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a98d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clt = KMeans(n_clusters = 10,random_state=0)   #no clue how many clusters! I am just lazy and don't want to label the data. \n",
    "k=clt.fit(in_f_tst)    #you can change to any of the other data types like the complex data here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba23852",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=k.fit_predict(in_f_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e0d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "from skimage import io\n",
    "io.imshow(color.label2rgb(out.reshape(2000,2000)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287a9763",
   "metadata": {},
   "source": [
    "We may not have learned anything scientific from the exercise, but now you can perhaps do actual work with these arrays. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6c69b7",
   "metadata": {},
   "source": [
    "hyvää työtä"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
